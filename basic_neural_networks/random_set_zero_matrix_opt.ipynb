{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the trianable ansatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import DFS\n",
    "inputStates, expectedStates = DFS().getInitialTargetStates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizing a minimization function suggested by ChatPGT and modified for our specific problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.15115758  0.64894976 -2.7497892  -1.56514938 -0.3248914 ]\n",
      " [ 2.74246052  0.         -1.04444073 -0.43276333 -1.79710542]\n",
      " [-1.4378175   0.39262192  2.30767816  0.          0.36155878]\n",
      " [-3.00532631  1.71912356 -0.         -1.490466    1.19882376]\n",
      " [ 2.36881599 -0.         -2.73885275  0.         -0.01882193]]\n",
      "[[ 2.02476993e+00 -1.39165575e+00 -2.24084724e+00  8.23960319e-09\n",
      "  -9.25868544e-01]\n",
      " [ 3.23124800e+00  0.00000000e+00 -1.37774309e+00  6.40500513e-09\n",
      "  -2.86396239e+00]\n",
      " [-9.49025806e-01 -2.37852617e+00  2.28364398e+00  0.00000000e+00\n",
      "  -1.27453800e+00]\n",
      " [-3.00532672e+00  3.69304453e+00  0.00000000e+00  2.34217013e-09\n",
      "   1.73770713e+00]\n",
      " [ 2.36881642e+00  0.00000000e+00 -2.73885174e+00  0.00000000e+00\n",
      "  -1.64839381e+00]]\n",
      "Optimized Matrix:\n",
      "[[ 0.20544562+0.97866853j  0.        +0.j          0.        +0.j\n",
      "  ...  0.        +0.j          0.        +0.j\n",
      "   0.        +0.j        ]\n",
      " [ 0.        +0.j         -0.3328996 -0.1440384j  -0.17823361+0.41220946j\n",
      "  ...  0.        +0.j          0.        +0.j\n",
      "   0.        +0.j        ]\n",
      " [ 0.        +0.j          0.14723041+0.17659914j  0.3018965 +0.73284707j\n",
      "  ...  0.        +0.j          0.        +0.j\n",
      "   0.        +0.j        ]\n",
      " ...\n",
      " [ 0.        +0.j          0.        +0.j          0.        +0.j\n",
      "  ...  0.3018965 +0.73284707j  0.14723041+0.17659914j\n",
      "   0.        +0.j        ]\n",
      " [ 0.        +0.j          0.        +0.j          0.        +0.j\n",
      "  ... -0.17823361+0.41220946j -0.3328996 -0.1440384j\n",
      "   0.        +0.j        ]\n",
      " [ 0.        +0.j          0.        +0.j          0.        +0.j\n",
      "  ...  0.        +0.j          0.        +0.j\n",
      "   0.20544562+0.97866853j]]\n",
      "fcnot loss = 6.322027276634104e-08\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import pennylane as qml\n",
    "\n",
    "I = np.eye(2)\n",
    "n_qubits = 6\n",
    "size_of_vec = 2**n_qubits\n",
    "num_layers = 5\n",
    "prcnt_drop = 17\n",
    "\n",
    "\n",
    "Udot = lambda s1, U, s2 : np.dot(np.conjugate(np.transpose(s1)),np.matmul(U,s2))\n",
    "\n",
    "def nestedKron(*args): # use \"*args\" to access an array of inputs\n",
    "    assert len(args) >= 2\n",
    "    temp = args[0]\n",
    "    for arg in args[1:]:\n",
    "        temp = np.kron(temp, arg)\n",
    "    return temp\n",
    "\n",
    "def get_random_weights(num_layers,prcnt_drop):\n",
    "    percent_to_zero = prcnt_drop\n",
    "    random_array = np.random.rand(5, num_layers)\n",
    "    random_array = 2 * np.pi * random_array - np.pi\n",
    "    mask = np.random.choice([0, 1], size=(5, num_layers), p=[percent_to_zero / 100, (100 - percent_to_zero) / 100])\n",
    "    return random_array * mask\n",
    "\n",
    "def U_ex(p):\n",
    "    from scipy.linalg import expm\n",
    "    X = [[0,1],[1,0]]\n",
    "    Y = np.array([[0,-1j],[1j,0]], dtype=np.complex128)\n",
    "    Z = [[1,0],[0,-1]]\n",
    "\n",
    "    H_ex = (1/4)*(np.kron(X,X) + np.kron(Y,Y) + np.kron(Z,Z))\n",
    "    # print(f'H_ex.type = {type(H_ex)}')\n",
    "    U_exchange = expm(-1j*p*H_ex) # p is now -pi to pi\n",
    "    return np.array(U_exchange)\n",
    "\n",
    "def single_layer_U(layer_weights):\n",
    "    \"\"\"Trainable circuit block.\"\"\"\n",
    "    firstPart = nestedKron(U_ex(layer_weights[0]), U_ex(layer_weights[1]), U_ex(layer_weights[2]))\n",
    "    secondPart = nestedKron(I, U_ex(layer_weights[3]), U_ex(layer_weights[4]), I)\n",
    "    return np.matmul(secondPart, firstPart)\n",
    "\n",
    "def get_matrix(weights):\n",
    "    totalMatrix = np.eye(size_of_vec)\n",
    "    for layer_weights in weights:\n",
    "        mat = single_layer_U(layer_weights)\n",
    "        totalMatrix = np.matmul(totalMatrix, mat)\n",
    "    return totalMatrix\n",
    "\n",
    "def square_loss(y_true, y_pred):\n",
    "    loss = 0\n",
    "    for i in range(len(expectedStates)):\n",
    "        # c = np.dot(np.conjugate(expectedStates[i]), predictedStates[i])\n",
    "        # c_2 = self.amp_sqrd(c)\n",
    "        fidelity = qml.math.fidelity_statevector(y_true[i], y_pred[i])\n",
    "        loss += (1 - fidelity) ** 2\n",
    "    loss /= len(expectedStates)\n",
    "    return 0.5*loss\n",
    "\n",
    "\n",
    "def f_cnot_loss(y_true, y_pred):\n",
    "    loss = 0\n",
    "    for i in range(len(expectedStates)):\n",
    "        fidelity = qml.math.fidelity_statevector(y_true[i], y_pred[i])\n",
    "        loss += fidelity\n",
    "    return np.sqrt(1 - (1/4)*abs(loss))\n",
    "\n",
    "# Define the correct operations you want the matrix to perform on basis vectors\n",
    "def target_operations(non_zero_parameters, inputStates, A):\n",
    "    param = np.zeros_like(A.flatten())\n",
    "    param[A.flatten() != 0] = non_zero_parameters\n",
    "    parameters = np.reshape(param, (num_layers, 5))\n",
    "    matrix = get_matrix(parameters)\n",
    "    # Perform matrix multiplication with basis vectors\n",
    "    results = []\n",
    "    for i in range(len(inputStates)):\n",
    "        results.append(np.matmul(matrix, inputStates[i]))\n",
    "\n",
    "    # Define the target operations you want (modify this based on your specific task)\n",
    "    target_result = np.array(expectedStates)\n",
    "\n",
    "    # Calculate the loss as the difference between the obtained result and the target result\n",
    "    loss = f_cnot_loss(target_result,results)#square_loss(target_result, results)\n",
    "    return loss\n",
    "\n",
    "# Example: Set the number of basis vectors and their dimensionality\n",
    "num_vectors = 4\n",
    "vector_dimension = size_of_vec\n",
    "\n",
    "# Generate random basis vectors and target result\n",
    "basis_vectors = np.array(inputStates)\n",
    "target_result = np.array(expectedStates)\n",
    "\n",
    "# Flatten the matrix parameters for optimization\n",
    "initial_parameters = get_random_weights(num_layers,prcnt_drop)\n",
    "non_zero_parameters = initial_parameters.flatten()[initial_parameters.flatten() != 0]\n",
    "print(initial_parameters)\n",
    "# Use scipy's minimize function to optimize the parameters\n",
    "result = minimize(target_operations,non_zero_parameters, args=(basis_vectors,initial_parameters,), method='L-BFGS-B')\n",
    "#print(result.x)\n",
    "# Reshape the optimized parameters back into the matrix form\n",
    "param = np.zeros_like(initial_parameters.flatten())\n",
    "param[initial_parameters.flatten() != 0] = result.x\n",
    "optimized_results = np.reshape(param, (num_layers, 5))\n",
    "print(optimized_results)\n",
    "optimized_matrix = get_matrix(optimized_results)\n",
    "\n",
    "print(\"Optimized Matrix:\")\n",
    "#for i in optimized_matrix:\n",
    "#    print(i)\n",
    "print(optimized_matrix)\n",
    "\n",
    "predStates = [np.matmul(optimized_matrix, mat) for mat in inputStates]\n",
    "print(f\"fcnot loss = {f_cnot_loss(expectedStates, predStates)}\")\n",
    "#print(f\"square loss = {square_loss(expectedStates, predStates)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
